{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f956e903",
   "metadata": {},
   "source": [
    "1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "243c5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from plotly.offline import plot\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, QuantileTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657db6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6da5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "# sales = pd.read_excel('Sales.xlsx', dtype={'OrderDate': str, 'ShipDate': str})\n",
    "sales = pd.read_excel('Sales.xlsx')\n",
    "customer = pd.read_excel('Customer.xlsx')\n",
    "product = pd.read_excel('Product.xlsx')\n",
    "territories = pd.read_excel('Territories.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb65ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†–∞–∑–º–µ—Ä –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: (58189, 50)\n",
      "\n",
      "–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\n",
      "   ProductKey  OrderDate   ShipDate  CustomerKey  PromotionKey  \\\n",
      "0         310 2014-01-01 2014-01-08        21768             1   \n",
      "1         346 2014-01-01 2014-01-08        28389             1   \n",
      "2         346 2014-01-01 2014-01-08        25863             1   \n",
      "3         336 2014-01-01 2014-01-08        14501             1   \n",
      "4         346 2014-01-01 2014-01-08        11003             1   \n",
      "\n",
      "   SalesTerritoryKey SalesOrderNumber  SalesOrderLineNumber  OrderQuantity  \\\n",
      "0                  6          SO43697                     1              2   \n",
      "1                  7          SO43698                     1              2   \n",
      "2                  1          SO43699                     1              2   \n",
      "3                  4          SO43700                     1              2   \n",
      "4                  9          SO43701                     1              2   \n",
      "\n",
      "   UnitPrice  TotalProductCost  SalesAmount    TaxAmt FirstName  LastName  \\\n",
      "0  1789.1350         2171.2942    3578.2700  286.2616      Cole    Watson   \n",
      "1  1699.9950         1912.1544    3399.9900  271.9992   Rachael  Martinez   \n",
      "2  1699.9950         1912.1544    3399.9900  271.9992    Sydney    Wright   \n",
      "3   349.5491          413.1463     699.0982   55.9279     Ruben    Prasad   \n",
      "4  1699.9950         1912.1544    3399.9900  271.9992   Christy       Zhu   \n",
      "\n",
      "            FullName   BirthDate MaritalStatus Gender  YearlyIncome  \\\n",
      "0       Watson, Cole  1946-08-22             S      M         70000   \n",
      "1  Martinez, Rachael  1964-12-18             S      F         20000   \n",
      "2     Wright, Sydney  1946-12-03             S      F         40000   \n",
      "3      Prasad, Ruben  1938-05-13             M      M         80000   \n",
      "4       Zhu, Christy  1968-02-15             S      F         70000   \n",
      "\n",
      "   TotalChildren  NumberChildrenAtHome        Education    Occupation  \\\n",
      "0              5                     0        Bachelors    Management   \n",
      "1              3                     3      High School        Manual   \n",
      "2              5                     0      High School  Professional   \n",
      "3              4                     0  Graduate Degree    Management   \n",
      "4              0                     0        Bachelors  Professional   \n",
      "\n",
      "   HouseOwnerFlag  NumberCarsOwned         AddressLine1 DateFirstPurchase  \\\n",
      "0               1                3     601 Asilomar Dr.        2005-07-01   \n",
      "1               0                0   14, avenue du Port        2005-07-01   \n",
      "2               1                3  4193 E. 28th Street        2005-07-01   \n",
      "3               1                2    249 Alexander Pl.        2005-07-01   \n",
      "4               0                1     1825 Village Pl.        2005-07-01   \n",
      "\n",
      "  CommuteDistance   CustomerCity CustomerStateCode      CustomerState  \\\n",
      "0       10+ Miles      Metchosin                BC   British Columbia   \n",
      "1       0-1 Miles         Pantin                93  Seine Saint Denis   \n",
      "2       10+ Miles        Lebanon                OR             Oregon   \n",
      "3       1-2 Miles  Beverly Hills                CA         California   \n",
      "4      5-10 Miles     North Ryde               NSW    New South Wales   \n",
      "\n",
      "  CustomerCountry              ProductName     SubCategory Category  \\\n",
      "0          Canada         Road-150 Red, 62      Road Bikes    Bikes   \n",
      "1          France  Mountain-100 Silver, 44  Mountain Bikes    Bikes   \n",
      "2   United States  Mountain-100 Silver, 44  Mountain Bikes    Bikes   \n",
      "3   United States       Road-650 Black, 62      Road Bikes    Bikes   \n",
      "4       Australia  Mountain-100 Silver, 44  Mountain Bikes    Bikes   \n",
      "\n",
      "   StandardCost   Color  ListPrice  DaysToManufacture ProductLine  \\\n",
      "0     2171.2942     Red  3578.2700                  4        Road   \n",
      "1     1912.1544  Silver  3399.9900                  4    Mountain   \n",
      "2     1912.1544  Silver  3399.9900                  4    Mountain   \n",
      "3      413.1463   Black   699.0982                  4        Road   \n",
      "4     1912.1544  Silver  3399.9900                  4    Mountain   \n",
      "\n",
      "      ModelName                                              Photo  \\\n",
      "0      Road-150  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "1  Mountain-100  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "2  Mountain-100  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "3      Road-650  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "4  Mountain-100  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "\n",
      "                                  ProductDescription  StartDate     Region  \\\n",
      "0  This bike is ridden by race winners. Developed... 2005-07-01     Canada   \n",
      "1  Top-of-the-line competition mountain bike. Per... 2005-07-01     France   \n",
      "2  Top-of-the-line competition mountain bike. Per... 2005-07-01  Northwest   \n",
      "3  Value-priced bike with many features of our to... 2005-07-01  Southwest   \n",
      "4  Top-of-the-line competition mountain bike. Per... 2005-07-01  Australia   \n",
      "\n",
      "         Country          Group  \\\n",
      "0         Canada  North America   \n",
      "1         France         Europe   \n",
      "2  United States  North America   \n",
      "3  United States  North America   \n",
      "4      Australia        Pacific   \n",
      "\n",
      "                                         RegionImage  \\\n",
      "0  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "1  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "2  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "3  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "4  http://www.avising.com/me/LearnPBI/DataSources...   \n",
      "\n",
      "                                         Region Info  \n",
      "0               https://en.wikipedia.org/wiki/Canada  \n",
      "1               https://en.wikipedia.org/wiki/France  \n",
      "2  https://en.wikipedia.org/wiki/Northwestern_Uni...  \n",
      "3  https://en.wikipedia.org/wiki/Southwestern_Uni...  \n",
      "4            https://en.wikipedia.org/wiki/Australia  \n"
     ]
    }
   ],
   "source": [
    "# –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "merged_data = sales.merge(customer, on='CustomerKey', how='left') \\\n",
    "                  .merge(product, on='ProductKey', how='left') \\\n",
    "                  .merge(territories, left_on='SalesTerritoryKey', right_on='SalesTerritoryKey', how='left')\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞\n",
    "print(\"–†–∞–∑–º–µ—Ä –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:\", merged_data.shape)\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "print(merged_data.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d158d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58189 entries, 0 to 58188\n",
      "Data columns (total 50 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   ProductKey            58189 non-null  int64         \n",
      " 1   OrderDate             58189 non-null  datetime64[ns]\n",
      " 2   ShipDate              58189 non-null  datetime64[ns]\n",
      " 3   CustomerKey           58189 non-null  int64         \n",
      " 4   PromotionKey          58189 non-null  int64         \n",
      " 5   SalesTerritoryKey     58189 non-null  int64         \n",
      " 6   SalesOrderNumber      58189 non-null  object        \n",
      " 7   SalesOrderLineNumber  58189 non-null  int64         \n",
      " 8   OrderQuantity         58189 non-null  int64         \n",
      " 9   UnitPrice             58189 non-null  float64       \n",
      " 10  TotalProductCost      58189 non-null  float64       \n",
      " 11  SalesAmount           58189 non-null  float64       \n",
      " 12  TaxAmt                58189 non-null  float64       \n",
      " 13  FirstName             58189 non-null  object        \n",
      " 14  LastName              58189 non-null  object        \n",
      " 15  FullName              58189 non-null  object        \n",
      " 16  BirthDate             58189 non-null  object        \n",
      " 17  MaritalStatus         58189 non-null  object        \n",
      " 18  Gender                58189 non-null  object        \n",
      " 19  YearlyIncome          58189 non-null  int64         \n",
      " 20  TotalChildren         58189 non-null  int64         \n",
      " 21  NumberChildrenAtHome  58189 non-null  int64         \n",
      " 22  Education             58189 non-null  object        \n",
      " 23  Occupation            58189 non-null  object        \n",
      " 24  HouseOwnerFlag        58189 non-null  int64         \n",
      " 25  NumberCarsOwned       58189 non-null  int64         \n",
      " 26  AddressLine1          58189 non-null  object        \n",
      " 27  DateFirstPurchase     58189 non-null  object        \n",
      " 28  CommuteDistance       58189 non-null  object        \n",
      " 29  CustomerCity          58189 non-null  object        \n",
      " 30  CustomerStateCode     58189 non-null  object        \n",
      " 31  CustomerState         58189 non-null  object        \n",
      " 32  CustomerCountry       58189 non-null  object        \n",
      " 33  ProductName           58189 non-null  object        \n",
      " 34  SubCategory           58189 non-null  object        \n",
      " 35  Category              58189 non-null  object        \n",
      " 36  StandardCost          58189 non-null  float64       \n",
      " 37  Color                 30747 non-null  object        \n",
      " 38  ListPrice             58189 non-null  float64       \n",
      " 39  DaysToManufacture     58189 non-null  int64         \n",
      " 40  ProductLine           58189 non-null  object        \n",
      " 41  ModelName             58189 non-null  object        \n",
      " 42  Photo                 58189 non-null  object        \n",
      " 43  ProductDescription    58189 non-null  object        \n",
      " 44  StartDate             58189 non-null  datetime64[ns]\n",
      " 45  Region                58189 non-null  object        \n",
      " 46  Country               58189 non-null  object        \n",
      " 47  Group                 58189 non-null  object        \n",
      " 48  RegionImage           58189 non-null  object        \n",
      " 49  Region Info           58189 non-null  object        \n",
      "dtypes: datetime64[ns](3), float64(6), int64(12), object(29)\n",
      "memory usage: 22.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''5. –ü–µ—á–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "print(\"\\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n"
     ]
    }
   ],
   "source": [
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "merged_data.to_csv('6_merged_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f829218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cc1d182",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\u001b[39;00m\n\u001b[32m      2\u001b[39m merged_data[\u001b[33m'\u001b[39m\u001b[33mProfit\u001b[39m\u001b[33m'\u001b[39m] = merged_data[\u001b[33m'\u001b[39m\u001b[33mSalesAmount\u001b[39m\u001b[33m'\u001b[39m] - merged_data[\u001b[33m'\u001b[39m\u001b[33mTotalProductCost\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m merged_data[\u001b[33m'\u001b[39m\u001b[33mOrderYear\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mmerged_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mOrderDate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m.year\n\u001b[32m      4\u001b[39m merged_data[\u001b[33m'\u001b[39m\u001b[33mOrderMonth\u001b[39m\u001b[33m'\u001b[39m] = merged_data[\u001b[33m'\u001b[39m\u001b[33mOrderDate\u001b[39m\u001b[33m'\u001b[39m].dt.month\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\–í–®–≠\\AD‚îÇ5‚îÇ03.09.25‚îÇVNIIT-31\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:6321\u001b[39m, in \u001b[36mNDFrame.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   6315\u001b[39m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._internal_names_set\n\u001b[32m   6316\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._metadata\n\u001b[32m   6317\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessors\n\u001b[32m   6318\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6319\u001b[39m ):\n\u001b[32m   6320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[32m-> \u001b[39m\u001b[32m6321\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\–í–®–≠\\AD‚îÇ5‚îÇ03.09.25‚îÇVNIIT-31\\venv\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[39m, in \u001b[36mCachedAccessor.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessor\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m accessor_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;28mobject\u001b[39m.\u001b[34m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m._name, accessor_obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\–í–®–≠\\AD‚îÇ5‚îÇ03.09.25‚îÇVNIIT-31\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:643\u001b[39m, in \u001b[36mCombinedDatetimelikeProperties.__new__\u001b[39m\u001b[34m(cls, data)\u001b[39m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data.dtype, PeriodDtype):\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "merged_data['Profit'] = merged_data['SalesAmount'] - merged_data['TotalProductCost']\n",
    "merged_data['OrderYear'] = merged_data['OrderDate'].dt.year\n",
    "merged_data['OrderMonth'] = merged_data['OrderDate'].dt.month\n",
    "\n",
    "print(\"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã.\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {merged_data.shape}\")\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99ec117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "columns_to_drop = [\n",
    "    'Photo',\n",
    "    'ProductDescription',\n",
    "    'NumberChildrenAtHome',\n",
    "    'AddressLine1',\n",
    "    'RegionImage',\n",
    "    'RegionInfo',\n",
    "    'CustomerStateCode',\n",
    "    \n",
    "    'SalesOrderLineNumber',\n",
    "    'StandardCost',  # —Ä–∞–≤–µ–Ω TotalProductCost\n",
    "    'ListPrice',     # —Ä–∞–≤–µ–Ω SalesAmount\n",
    "    'PromotionKey',\n",
    "    'CustomerCountry', # —Ä–∞–≤–µ–Ω Country\n",
    "    'Group'\n",
    "]\n",
    "\n",
    "merged_data = merged_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''5. –ü–µ—á–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "print(\"\\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaafd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤'''\n",
    "'''–ü–µ—á–∞—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ'''\n",
    "print(\"\\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:\")\n",
    "print(merged_data.isnull().sum())\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de368c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ª—é–±—ã–º–∏ –ø—Ä–æ–ø—É—Å–∫–∞–º–∏\n",
    "merged_data.dropna(inplace=True)\n",
    "merged_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21fd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "merged_data['UnitPrice'] = pd.to_numeric(merged_data['UnitPrice'], errors='coerce')\n",
    "merged_data['TotalProductCost'] = pd.to_numeric(merged_data['TotalProductCost'], errors='coerce')\n",
    "merged_data['SalesAmount'] = pd.to_numeric(merged_data['SalesAmount'], errors='coerce')\n",
    "merged_data['TaxAmt'] = pd.to_numeric(merged_data['TaxAmt'], errors='coerce')\n",
    "merged_data['YearlyIncome'] = pd.to_numeric(merged_data['YearlyIncome'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07221294",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤'''\n",
    "'''–ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'OrderDate' –∫ —Ç–∏–ø—É datetime'''\n",
    "# merged_data['OrderDate'] = pd.to_datetime(merged_data['OrderDate'], errors='coerce')\n",
    "# merged_data['ShipDate'] = pd.to_datetime(merged_data['ShipDate'], errors='coerce')\n",
    "# merged_data['BirthDate'] = pd.to_datetime(merged_data['BirthDate'], errors='coerce')\n",
    "\n",
    "date_columns = [col for col in merged_data.columns if 'Date' in col]\n",
    "for col in date_columns:\n",
    "    merged_data[col] = pd.to_datetime(merged_data[col], errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''5. –ü–µ—á–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "print(\"\\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(merged_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b03d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ece1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "merged_data.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ –û–ß–ò–°–¢–ö–ê –ò –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•\n",
    "print(\"üßπ –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•\")\n",
    "print(\"=\" * 50)\n",
    "df = data\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä\n",
    "initial_count = len(df)\n",
    "print(f\"üìä –ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {initial_count}\")\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "df = df.drop_duplicates()\n",
    "duplicates_removed = initial_count - len(df)\n",
    "print(f\"üìä –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "print(\"\\nüìä –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': missing_data,\n",
    "    '–ü—Ä–æ—Ü–µ–Ω—Ç': missing_percent\n",
    "}).sort_values('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', ascending=False)\n",
    "\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏\n",
    "missing_columns = missing_info[missing_info['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] > 0]\n",
    "if len(missing_columns) > 0:\n",
    "    print(\"–ö–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏:\")\n",
    "    display(missing_columns)\n",
    "else:\n",
    "    print(\"‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ\")\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "print(\"\\nüîß –ó–ê–ü–û–õ–ù–ï–ù–ò–ï –ü–†–û–ü–£–°–ö–û–í:\")\n",
    "if 'Color' in df.columns:\n",
    "    df['Color'] = df['Color'].fillna('Not Specified')\n",
    "    print(\"‚úÖ Color: –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º 'Not Specified'\")\n",
    "\n",
    "if 'SubCategory' in df.columns:\n",
    "    df['SubCategory'] = df['SubCategory'].fillna('Unknown')\n",
    "    df['Category'] = df['Category'].fillna('Unknown')\n",
    "    print(\"‚úÖ Category/SubCategory: –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º 'Unknown'\")\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"\\nüîÑ –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –¢–ò–ü–û–í –î–ê–ù–ù–´–•:\")\n",
    "\n",
    "date_columns = ['OrderDate', 'ShipDate', 'BirthDate', 'DateFirstPurchase', 'StartDate']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        print(f\"‚úÖ {col}: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ datetime\")\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "numeric_columns = ['YearlyIncome', 'TotalChildren', 'NumberChildrenAtHome', \n",
    "                  'NumberCarsOwned', 'StandardCost', 'ListPrice', 'DaysToManufacture',\n",
    "                  'OrderQuantity', 'UnitPrice', 'TotalProductCost', 'SalesAmount', 'TaxAmt']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        print(f\"‚úÖ {col}: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "print(\"\\nüéØ –°–û–ó–î–ê–ù–ò–ï –ù–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í:\")\n",
    "\n",
    "if 'OrderDate' in df.columns:\n",
    "    df['OrderYear'] = df['OrderDate'].dt.year\n",
    "    df['OrderMonth'] = df['OrderDate'].dt.month\n",
    "    df['OrderQuarter'] = df['OrderDate'].dt.quarter\n",
    "    df['OrderDayOfWeek'] = df['OrderDate'].dt.day_name()\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ OrderDate\")\n",
    "    \n",
    "    # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ—Å—Ç–∞–≤–∫–∏\n",
    "    if 'ShipDate' in df.columns:\n",
    "        df['DeliveryDays'] = (df['ShipDate'] - df['OrderDate']).dt.days\n",
    "        print(\"‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫ DeliveryDays\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤\n",
    "if 'YearlyIncome' in df.columns:\n",
    "    df['IncomeSegment'] = pd.cut(df['YearlyIncome'], \n",
    "                               bins=[0, 50000, 80000, 100000, float('inf')],\n",
    "                               labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω IncomeSegment\")\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞ –∫–ª–∏–µ–Ω—Ç–∞\n",
    "if 'BirthDate' in df.columns:\n",
    "    df['Age'] = (datetime.now() - df['BirthDate']).dt.days // 365\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫ Age\")\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏\n",
    "if 'SalesAmount' in df.columns and 'TotalProductCost' in df.columns:\n",
    "    df['Profit'] = df['SalesAmount'] - df['TotalProductCost']\n",
    "    df['ProfitMargin'] = (df['Profit'] / df['SalesAmount']) * 100\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω—ã Profit –∏ ProfitMargin\")\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –æ–±—â–µ–π —Å—É–º–º—ã, –µ—Å–ª–∏ –Ω–µ—Ç\n",
    "if 'UnitPrice' in df.columns and 'OrderQuantity' in df.columns and 'TotalAmount' not in df.columns:\n",
    "    df['TotalAmount'] = df['UnitPrice'] * df['OrderQuantity']\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω TotalAmount\")\n",
    "\n",
    "print(f\"\\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢ –û–ß–ò–°–¢–ö–ò:\")\n",
    "print(f\"   ‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {initial_count} —Å—Ç—Ä–æ–∫\")\n",
    "print(f\"   ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫\") \n",
    "print(f\"   ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}\")\n",
    "print(f\"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\nüëÄ –ü–†–ï–í–¨–Æ –û–ß–ò–©–ï–ù–ù–´–• –î–ê–ù–ù–´–•:\")\n",
    "display(df.head(3))\n",
    "\n",
    "print(\"\\nüìã –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–• –ü–û–°–õ–ï –û–ß–ò–°–¢–ö–ò:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n‚úÖ –î–ê–ù–ù–´–ï –û–ß–ò–©–ï–ù–´ –ò –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–´!\")\n",
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "data_cleaned.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "merged_data.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28caf3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "merged_data.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b251c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ad50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö'''\n",
    "data = pd.read_csv('merged_sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77de037",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_excel('output_file.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081db763",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'''\n",
    "duplicates_count = data_cleaned.duplicated().sum()\n",
    "print(f\"\\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}\")\n",
    "data_cleaned = data_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''–ü—Ä–æ—Å–º–æ—Ç—Ä –ø–µ—Ä–≤—ã—Ö 5 —Å—Ç—Ä–æ–∫'''\n",
    "print(\"–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫/—Å—Ç–æ–ª–±—Ü–æ–≤'''\n",
    "df_dropped_rows = df.dropna()\n",
    "df_dropped_cols = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏'''\n",
    "data_cleaned = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4927c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'''\n",
    "duplicates_count = data_cleaned.duplicated().sum()\n",
    "print(f\"\\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}\")\n",
    "data_cleaned = data_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏'''\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df_mean_filled = pd.DataFrame(mean_imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f49ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa44c191",
   "metadata": {},
   "source": [
    "–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''4. –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤'''\n",
    "'''–ü—Ä–∏–º–µ—Ä: —É–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ —á–∏—Å–ª–æ–≤–æ–º —Å—Ç–æ–ª–±—Ü–µ 'value_column'''\n",
    "Q1 = data_cleaned['Price'].quantile(0.25)\n",
    "Q3 = data_cleaned['Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "data_cleaned = data_cleaned[(data_cleaned['Price'] >= lower_bound) &\n",
    "                             (data_cleaned['Price'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ec5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv('merged_data.csv')  \n",
    "\n",
    "# –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞: –∫–∞–∫–∏–µ —Å—Ç–æ–ª–±—Ü—ã —á–∏—Å–ª–æ–≤—ã–µ\n",
    "print(\"–ß–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã:\")\n",
    "print(numeric_df.columns.tolist())\n",
    "\n",
    "# –ï—Å–ª–∏ —á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –µ—Å—Ç—å, –ø—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é\n",
    "if numeric_df.empty:\n",
    "    print(\"–ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.\")\n",
    "else:\n",
    "    # 1. Z-score Normalization\n",
    "    z_score_scaler = StandardScaler()\n",
    "    z_score_normalized = z_score_scaler.fit_transform(numeric_df)\n",
    "\n",
    "    # 2. Min-Max Normalization\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    min_max_normalized = min_max_scaler.fit_transform(numeric_df)\n",
    "\n",
    "    # 3. Robust Scaler\n",
    "    robust_scaler = RobustScaler()\n",
    "    robust_normalized = robust_scaler.fit_transform(numeric_df)\n",
    "\n",
    "    # 4. MaxAbs Scaler\n",
    "    max_abs_scaler = MaxAbsScaler()\n",
    "    max_abs_normalized = max_abs_scaler.fit_transform(numeric_df)\n",
    "\n",
    "    # 5. Log Transformation (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)\n",
    "    positive_data = numeric_df[numeric_df > 0].fillna(0)\n",
    "    log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "    log_transformed = log_transformer.fit_transform(positive_data)\n",
    "\n",
    "    # 6. Quantile Transformation\n",
    "    quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
    "    quantile_normalized = quantile_transformer.fit_transform(numeric_df)\n",
    "\n",
    "    # 7. Decimal Scaling\n",
    "    def decimal_scaling(data):\n",
    "        j = np.ceil(np.log10(np.abs(data).max(axis=0) + 1))\n",
    "        return data / (10 ** j)\n",
    "\n",
    "    decimal_scaled = decimal_scaling(numeric_df.values)\n",
    "\n",
    "    # 8. Softmax (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)\n",
    "    def softmax(x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=0))\n",
    "        return exp_x / exp_x.sum(axis=0)\n",
    "\n",
    "    softmax_normalized = softmax(numeric_df.values)\n",
    "\n",
    "    '''–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'''\n",
    "    print(\"\\nZ-score Normalized (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫):\\n\", z_score_normalized[:5])\n",
    "    print(\"\\nMin-Max Normalized (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫–∏):\\n\", min_max_normalized[:5])\n",
    "    print(\"\\nRobust Normalized (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫–∏):\\n\", robust_normalized[:5])\n",
    "    print(\"\\nMaxAbs Normalized (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫–∏):\\n\", max_abs_normalized[:5])\n",
    "    print(\"\\nLog Transformed (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫–∏):\\n\", log_transformed[:5])\n",
    "    print(\"\\nQuantile Normalized (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫–∏):\\n\", quantile_normalized[:5])\n",
    "    print(\"\\nDecimal Scaled (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫–∏):\\n\", decimal_scaled[:5])\n",
    "    print(\"\\nSoftmax Normalized (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫–∏):\\n\", softmax_normalized[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32969a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. –¢–µ—Å—Ç –ì—Ä–∞–±–±—Å–∞ (Grubbs' Test)'''\n",
    "def grubbs_test(data):\n",
    "    N = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    G = max(abs(data - mean)) / std_dev\n",
    "    critical_value = stats.t.ppf(1 - 0.05 / (2 * N), N - 2)  # –¥–ª—è 5% —É—Ä–æ–≤–Ω—è –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "    return G, G > critical_value\n",
    "\n",
    "grubbs_result = grubbs_test(data)\n",
    "print(\"Grubbs' Test: G =\", grubbs_result[0], \"Is outlier?\", grubbs_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983922f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. –¢–µ—Å—Ç –î–∏–∫—Å–æ–Ω–∞ (Dixon's Q Test)'''\n",
    "def dixon_test(data):\n",
    "    data_sorted = np.sort(data)\n",
    "    Q_low = (data_sorted[1] - data_sorted[0]) / (data_sorted[-1] - data_sorted[0])\n",
    "    Q_high = (data_sorted[-1] - data_sorted[-2]) / (data_sorted[-1] - data_sorted[0])\n",
    "    critical_value = 0.5  # –ü–æ—Ä–æ–≥ –¥–ª—è Q (–∏—Å—Ö–æ–¥—è –∏–∑ —Ç–∞–±–ª–∏—Ü –¥–ª—è n = 10)\n",
    "    return Q_low > critical_value or Q_high > critical_value\n",
    "\n",
    "dixon_result = dixon_test(data)\n",
    "print(\"Dixon's Q Test: Is outlier?\", dixon_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''4. –¢–µ—Å—Ç –†–æ–∑–µ–Ω–±–∞—É–º–∞ (Rosner's Test)'''\n",
    "def rosner_test(data, max_outliers=1):\n",
    "    N = len(data)\n",
    "    data_sorted = np.sort(data)\n",
    "    for i in range(max_outliers):\n",
    "        mean = np.mean(data_sorted)\n",
    "        std_dev = np.std(data_sorted)\n",
    "        threshold = mean + (i + 1) * std_dev\n",
    "        if data_sorted[-(i + 1)] > threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "rosner_result = rosner_test(data)\n",
    "print(\"Rosner's Test: Is outlier?\", rosner_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b36eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''5. –¢–µ—Å—Ç –¢—å–æ-–ì–µ–Ω—Ç–µ—Ä–∞ (Tietjen-Moore Test)'''\n",
    "def tietjen_moore_test(data):\n",
    "    N = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    z_scores = (data - mean) / std_dev\n",
    "    return np.any(np.abs(z_scores) > 3)  # –ü–æ—Ä–æ–≥ Z-–∑–Ω–∞—á–µ–Ω–∏—è\n",
    "\n",
    "tietjen_moore_result = tietjen_moore_test(data)\n",
    "print(\"Tietjen-Moore Test: Is outlier?\", tietjen_moore_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0490dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. –¢–µ—Å—Ç –°—Ç—å—é–¥–µ–Ω—Ç–∞ (Student's t-test)'''\n",
    "t_statistic, p_value = stats.ttest_1samp(data, 0)\n",
    "print(\"Student's t-test: t-statistic =\", t_statistic, \", p-value =\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''7. –¢–µ—Å—Ç –°–ø–∏—Ä–º–µ–Ω–∞ (Spearman's Rank Correlation Coefficient)'''\n",
    "spearman_corr, spearman_p = stats.spearmanr(data, np.arange(len(data)))\n",
    "print(\"Spearman's Test: Correlation =\", spearman_corr, \", p-value =\", spearman_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''8. –¢–µ—Å—Ç –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏ (Mann-Whitney U Test)'''\n",
    "# –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Å–æ–∑–¥–∞–¥–∏–º –¥–≤–∞ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "data1 = np.array([1, 2, 3, 4, 5])\n",
    "data2 = np.array([5, 6, 7, 8, 9])\n",
    "mann_whitney_result = stats.mannwhitneyu(data1, data2)\n",
    "print(\"Mann-Whitney U Test: U-statistic =\", mann_whitney_result.statistic, \", p-value =\", mann_whitney_result.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''9. –¢–µ—Å—Ç –®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞ (Shapiro-Wilk Test)'''\n",
    "shapiro_stat, shapiro_p = stats.shapiro(data)\n",
    "print(\"Shapiro-Wilk Test: W-statistic =\", shapiro_stat, \", p-value =\", shapiro_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3510c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''10. –¢–µ—Å—Ç –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞ (Kolmogorov-Smirnov Test)'''\n",
    "ks_stat, ks_p = stats.kstest(data, 'norm', args=(np.mean(data), np.std(data)))\n",
    "print(\"Kolmogorov-Smirnov Test: D-statistic =\", ks_stat, \", p-value =\", ks_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611059a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. –ö—Ä–∏—Ç–µ—Ä–∏–π –®–æ–≤–µ–Ω–µ (Chauvenet's Criterion)'''\n",
    "def chauvenet_test(data):\n",
    "    N = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    d = abs(data - mean) / std_dev\n",
    "    p_values = 1 / (2 * N * np.exp(0.5 * (d**2)))\n",
    "    return np.any(p_values < 0.5)\n",
    "\n",
    "chauvenet_result = chauvenet_test(data)\n",
    "print(\"Chauvenet's Criterion: Is outlier?\", chauvenet_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71cbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ –û–ß–ò–°–¢–ö–ê –ò –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•\n",
    "print(\"üßπ –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•\")\n",
    "print(\"=\" * 50)\n",
    "df = data\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä\n",
    "initial_count = len(df)\n",
    "print(f\"üìä –ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {initial_count}\")\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "df = df.drop_duplicates()\n",
    "duplicates_removed = initial_count - len(df)\n",
    "print(f\"üìä –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "print(\"\\nüìä –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': missing_data,\n",
    "    '–ü—Ä–æ—Ü–µ–Ω—Ç': missing_percent\n",
    "}).sort_values('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', ascending=False)\n",
    "\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏\n",
    "missing_columns = missing_info[missing_info['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] > 0]\n",
    "if len(missing_columns) > 0:\n",
    "    print(\"–ö–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏:\")\n",
    "    display(missing_columns)\n",
    "else:\n",
    "    print(\"‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ\")\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "print(\"\\nüîß –ó–ê–ü–û–õ–ù–ï–ù–ò–ï –ü–†–û–ü–£–°–ö–û–í:\")\n",
    "if 'Color' in df.columns:\n",
    "    df['Color'] = df['Color'].fillna('Not Specified')\n",
    "    print(\"‚úÖ Color: –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º 'Not Specified'\")\n",
    "\n",
    "if 'SubCategory' in df.columns:\n",
    "    df['SubCategory'] = df['SubCategory'].fillna('Unknown')\n",
    "    df['Category'] = df['Category'].fillna('Unknown')\n",
    "    print(\"‚úÖ Category/SubCategory: –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º 'Unknown'\")\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"\\nüîÑ –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –¢–ò–ü–û–í –î–ê–ù–ù–´–•:\")\n",
    "\n",
    "date_columns = ['OrderDate', 'ShipDate', 'BirthDate', 'DateFirstPurchase', 'StartDate']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        print(f\"‚úÖ {col}: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ datetime\")\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "numeric_columns = ['YearlyIncome', 'TotalChildren', 'NumberChildrenAtHome', \n",
    "                  'NumberCarsOwned', 'StandardCost', 'ListPrice', 'DaysToManufacture',\n",
    "                  'OrderQuantity', 'UnitPrice', 'TotalProductCost', 'SalesAmount', 'TaxAmt']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        print(f\"‚úÖ {col}: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "print(\"\\nüéØ –°–û–ó–î–ê–ù–ò–ï –ù–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í:\")\n",
    "\n",
    "if 'OrderDate' in df.columns:\n",
    "    df['OrderYear'] = df['OrderDate'].dt.year\n",
    "    df['OrderMonth'] = df['OrderDate'].dt.month\n",
    "    df['OrderQuarter'] = df['OrderDate'].dt.quarter\n",
    "    df['OrderDayOfWeek'] = df['OrderDate'].dt.day_name()\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ OrderDate\")\n",
    "    \n",
    "    # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ—Å—Ç–∞–≤–∫–∏\n",
    "    if 'ShipDate' in df.columns:\n",
    "        df['DeliveryDays'] = (df['ShipDate'] - df['OrderDate']).dt.days\n",
    "        print(\"‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫ DeliveryDays\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤\n",
    "if 'YearlyIncome' in df.columns:\n",
    "    df['IncomeSegment'] = pd.cut(df['YearlyIncome'], \n",
    "                               bins=[0, 50000, 80000, 100000, float('inf')],\n",
    "                               labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω IncomeSegment\")\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞ –∫–ª–∏–µ–Ω—Ç–∞\n",
    "if 'BirthDate' in df.columns:\n",
    "    df['Age'] = (datetime.now() - df['BirthDate']).dt.days // 365\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫ Age\")\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏\n",
    "if 'SalesAmount' in df.columns and 'TotalProductCost' in df.columns:\n",
    "    df['Profit'] = df['SalesAmount'] - df['TotalProductCost']\n",
    "    df['ProfitMargin'] = (df['Profit'] / df['SalesAmount']) * 100\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω—ã Profit –∏ ProfitMargin\")\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –æ–±—â–µ–π —Å—É–º–º—ã, –µ—Å–ª–∏ –Ω–µ—Ç\n",
    "if 'UnitPrice' in df.columns and 'OrderQuantity' in df.columns and 'TotalAmount' not in df.columns:\n",
    "    df['TotalAmount'] = df['UnitPrice'] * df['OrderQuantity']\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω TotalAmount\")\n",
    "\n",
    "print(f\"\\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢ –û–ß–ò–°–¢–ö–ò:\")\n",
    "print(f\"   ‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {initial_count} —Å—Ç—Ä–æ–∫\")\n",
    "print(f\"   ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫\") \n",
    "print(f\"   ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}\")\n",
    "print(f\"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\nüëÄ –ü–†–ï–í–¨–Æ –û–ß–ò–©–ï–ù–ù–´–• –î–ê–ù–ù–´–•:\")\n",
    "display(df.head(3))\n",
    "\n",
    "print(\"\\nüìã –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–• –ü–û–°–õ–ï –û–ß–ò–°–¢–ö–ò:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n‚úÖ –î–ê–ù–ù–´–ï –û–ß–ò–©–ï–ù–´ –ò –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–´!\")\n",
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "data_cleaned.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32a856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•\n",
    "print(\"üîç –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"üìà –û–°–ù–û–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê (—á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏):\")\n",
    "print(f\"üìä –ù–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(numeric_cols)}\")\n",
    "\n",
    "if len(numeric_cols) > 0:\n",
    "    display(df[numeric_cols].describe())\n",
    "else:\n",
    "    print(\"‚ùå –ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nüìä –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ({len(categorical_cols)}):\")\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    for i, col in enumerate(categorical_cols[:8], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 8\n",
    "        unique_count = df[col].nunique()\n",
    "        print(f\"   {i}. {col}: {unique_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\")\n",
    "        if unique_count <= 10:\n",
    "            value_counts = df[col].value_counts()\n",
    "            print(f\"      –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {dict(value_counts)}\")\n",
    "        else:\n",
    "            print(f\"      –ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π: {list(df[col].unique()[:5])}\")\n",
    "    \n",
    "    if len(categorical_cols) > 8:\n",
    "        print(f\"   ... –∏ –µ—â–µ {len(categorical_cols) - 8} –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\")\n",
    "else:\n",
    "    print(\"‚ùå –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "date_cols = df.select_dtypes(include=['datetime64']).columns\n",
    "print(f\"\\nüïê –í–†–ï–ú–ï–ù–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ({len(date_cols)}):\")\n",
    "\n",
    "if len(date_cols) > 0:\n",
    "    for i, col in enumerate(date_cols, 1):\n",
    "        date_range = f\"{df[col].min().date()} - {df[col].max().date()}\"\n",
    "        print(f\"   {i}. {col}: {date_range}\")\n",
    "else:\n",
    "    print(\"‚ùå –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "\n",
    "# –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(f\"\\nüìã –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–•:\")\n",
    "print(f\"   ‚Ä¢ –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫\")\n",
    "print(f\"   ‚Ä¢ –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"      - –ß–∏—Å–ª–æ–≤—ã–µ: {len(numeric_cols)}\")\n",
    "print(f\"      - –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ: {len(categorical_cols)}\")\n",
    "print(f\"      - –í—Ä–µ–º–µ–Ω–Ω—ã–µ: {len(date_cols)}\")\n",
    "print(f\"      - –î—Ä—É–≥–∏–µ: {df.shape[1] - len(numeric_cols) - len(categorical_cols) - len(date_cols)}\")\n",
    "\n",
    "# –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "missing_total = df.isnull().sum().sum()\n",
    "missing_percent = (missing_total / (df.shape[0] * df.shape[1])) * 100\n",
    "print(f\"   ‚Ä¢ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {missing_total} ({missing_percent:.2f}%)\")\n",
    "\n",
    "print(\"\\nüëÄ –ü–ï–†–í–´–ï 3 –°–¢–†–û–ö–ò –î–ê–ù–ù–´–•:\")\n",
    "display(df.head(3))\n",
    "\n",
    "print(\"‚úÖ –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
