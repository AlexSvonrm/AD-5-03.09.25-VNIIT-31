{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f956e903",
   "metadata": {},
   "source": [
    "1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from plotly.offline import plot\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, QuantileTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657db6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "sales = pd.read_excel('Sales.xlsx', dtype={'OrderDate': str, 'ShipDate': str})\n",
    "customer = pd.read_excel('Customer.xlsx')\n",
    "product = pd.read_excel('Product.xlsx')\n",
    "territories = pd.read_excel('Territories.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb65ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "merged_data = sales.merge(customer, on='CustomerKey', how='left') \\\n",
    "                  .merge(product, on='ProductKey', how='left') \\\n",
    "                  .merge(territories, left_on='SalesTerritoryKey', right_on='SalesTerritoryKey', how='left')\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞\n",
    "print(\"–†–∞–∑–º–µ—Ä –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:\", merged_data.shape)\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "print(merged_data.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "merged_data.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤'''\n",
    "'''–ü–µ—á–∞—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ'''\n",
    "print(\"\\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:\")\n",
    "print(merged_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ad50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö'''\n",
    "data = pd.read_csv('merged_sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77de037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ª—é–±—ã–º–∏ –ø—Ä–æ–ø—É—Å–∫–∞–º–∏\n",
    "df.dropna(inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd37e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É —Å—Ç–æ–ª–±—Ü—É\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫-–¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# –ú–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Å—Ç–æ–ª–±—Ü—É –∏–ª–∏ –Ω–∞–±–æ—Ä—É —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "#df.drop_duplicates(subset=['column_name'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081db763",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'''\n",
    "duplicates_count = data_cleaned.duplicated().sum()\n",
    "print(f\"\\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}\")\n",
    "data_cleaned = data_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤'''\n",
    "'''–ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'date_column' –∫ —Ç–∏–ø—É datetime'''\n",
    "data_cleaned['date_column'] = pd.to_datetime(data_cleaned['date_column'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a4885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "merged_data['UnitPrice'] = pd.to_numeric(merged_data['UnitPrice'], errors='coerce')\n",
    "merged_data['TotalProductCost'] = pd.to_numeric(merged_data['TotalProductCost'], errors='coerce')\n",
    "merged_data['SalesAmount'] = pd.to_numeric(merged_data['SalesAmount'], errors='coerce')\n",
    "merged_data['TaxAmt'] = pd.to_numeric(merged_data['TaxAmt'], errors='coerce')\n",
    "merged_data['YearlyIncome'] = pd.to_numeric(merged_data['YearlyIncome'], errors='coerce')\n",
    "merged_data['ListPrice'] = pd.to_numeric(merged_data['ListPrice'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "merged_data['Profit'] = merged_data['SalesAmount'] - merged_data['TotalProductCost']\n",
    "merged_data['OrderYear'] = merged_data['OrderDate'].dt.year\n",
    "merged_data['OrderMonth'] = merged_data['OrderDate'].dt.month\n",
    "\n",
    "print(\"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã.\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {merged_data.shape}\")\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "merged_data.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878a5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''–ü—Ä–æ—Å–º–æ—Ç—Ä –ø–µ—Ä–≤—ã—Ö 5 —Å—Ç—Ä–æ–∫'''\n",
    "print(\"–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫/—Å—Ç–æ–ª–±—Ü–æ–≤'''\n",
    "df_dropped_rows = df.dropna()\n",
    "df_dropped_cols = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏'''\n",
    "data_cleaned = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4927c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤'''\n",
    "duplicates_count = data_cleaned.duplicated().sum()\n",
    "print(f\"\\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}\")\n",
    "data_cleaned = data_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4702c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤'''\n",
    "'''–ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'BirthDate' –∫ —Ç–∏–ø—É datetime'''\n",
    "data_cleaned['OrderDate'] = pd.to_datetime(data_cleaned['OrderDate'], errors='coerce')\n",
    "data_cleaned['ShipDate'] = pd.to_datetime(data_cleaned['ShipDate'], errors='coerce')\n",
    "data_cleaned['BirthDate'] = pd.to_datetime(data_cleaned['BirthDate'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏'''\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df_mean_filled = pd.DataFrame(mean_imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a0ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb02a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''–ü—Ä–æ—Å–º–æ—Ç—Ä –ø–µ—Ä–≤—ã—Ö 5 —Å—Ç—Ä–æ–∫'''\n",
    "print(\"–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f68116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''5. –ü–µ—á–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "print(\"\\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(data_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa96d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "data_cleaned.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1f98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''4. –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤'''\n",
    "'''–ü—Ä–∏–º–µ—Ä: —É–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ —á–∏—Å–ª–æ–≤–æ–º —Å—Ç–æ–ª–±—Ü–µ 'value_column'''\n",
    "Q1 = data_cleaned['Price'].quantile(0.25)\n",
    "Q3 = data_cleaned['Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "data_cleaned = data_cleaned[(data_cleaned['Price'] >= lower_bound) &\n",
    "                             (data_cleaned['Price'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ec5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö'''\n",
    "data = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "\n",
    "'''1. Z-score Normalization'''\n",
    "z_score_scaler = StandardScaler()\n",
    "z_score_normalized = z_score_scaler.fit_transform(data)\n",
    "\n",
    "'''2. Min-Max Normalization'''\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_normalized = min_max_scaler.fit_transform(data)\n",
    "\n",
    "'''3. Robust Scaler'''\n",
    "robust_scaler = RobustScaler()\n",
    "robust_normalized = robust_scaler.fit_transform(data)\n",
    "\n",
    "'''4. MaxAbs Scaler'''\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "max_abs_normalized = max_abs_scaler.fit_transform(data)\n",
    "\n",
    "'''5. Log Transformation'''\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "log_transformed = log_transformer.fit_transform(data)\n",
    "\n",
    "'''6. Quantile Transformation'''\n",
    "quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
    "quantile_normalized = quantile_transformer.fit_transform(data)\n",
    "\n",
    "'''7. Decimal Scaling'''\n",
    "def decimal_scaling(data):\n",
    "    j = np.ceil(np.log10(np.abs(data).max() + 1))\n",
    "    return data / (10 ** j)\n",
    "\n",
    "decimal_scaled = decimal_scaling(data)\n",
    "\n",
    "'''8. Softmax Normalization'''\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / exp_x.sum(axis=0)\n",
    "\n",
    "softmax_normalized = softmax(data)\n",
    "\n",
    "'''–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'''\n",
    "print(\"Z-score Normalized:\\n\", z_score_normalized)\n",
    "print(\"Min-Max Normalized:\\n\", min_max_normalized)\n",
    "print(\"Robust Normalized:\\n\", robust_normalized)\n",
    "print(\"MaxAbs Normalized:\\n\", max_abs_normalized)\n",
    "print(\"Log Transformed:\\n\", log_transformed)\n",
    "print(\"Quantile Normalized:\\n\", quantile_normalized)\n",
    "print(\"Decimal Scaled:\\n\", decimal_scaled)\n",
    "print(\"Softmax Normalized:\\n\", softmax_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. –¢–µ—Å—Ç –ì—Ä–∞–±–±—Å–∞ (Grubbs' Test)'''\n",
    "def grubbs_test(data):\n",
    "    N = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    G = max(abs(data - mean)) / std_dev\n",
    "    critical_value = stats.t.ppf(1 - 0.05 / (2 * N), N - 2)  # –¥–ª—è 5% —É—Ä–æ–≤–Ω—è –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n",
    "    return G, G > critical_value\n",
    "\n",
    "grubbs_result = grubbs_test(data)\n",
    "print(\"Grubbs' Test: G =\", grubbs_result[0], \"Is outlier?\", grubbs_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983922f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2. –¢–µ—Å—Ç –î–∏–∫—Å–æ–Ω–∞ (Dixon's Q Test)'''\n",
    "def dixon_test(data):\n",
    "    data_sorted = np.sort(data)\n",
    "    Q_low = (data_sorted[1] - data_sorted[0]) / (data_sorted[-1] - data_sorted[0])\n",
    "    Q_high = (data_sorted[-1] - data_sorted[-2]) / (data_sorted[-1] - data_sorted[0])\n",
    "    critical_value = 0.5  # –ü–æ—Ä–æ–≥ –¥–ª—è Q (–∏—Å—Ö–æ–¥—è –∏–∑ —Ç–∞–±–ª–∏—Ü –¥–ª—è n = 10)\n",
    "    return Q_low > critical_value or Q_high > critical_value\n",
    "\n",
    "dixon_result = dixon_test(data)\n",
    "print(\"Dixon's Q Test: Is outlier?\", dixon_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''4. –¢–µ—Å—Ç –†–æ–∑–µ–Ω–±–∞—É–º–∞ (Rosner's Test)'''\n",
    "def rosner_test(data, max_outliers=1):\n",
    "    N = len(data)\n",
    "    data_sorted = np.sort(data)\n",
    "    for i in range(max_outliers):\n",
    "        mean = np.mean(data_sorted)\n",
    "        std_dev = np.std(data_sorted)\n",
    "        threshold = mean + (i + 1) * std_dev\n",
    "        if data_sorted[-(i + 1)] > threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "rosner_result = rosner_test(data)\n",
    "print(\"Rosner's Test: Is outlier?\", rosner_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b36eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''5. –¢–µ—Å—Ç –¢—å–æ-–ì–µ–Ω—Ç–µ—Ä–∞ (Tietjen-Moore Test)'''\n",
    "def tietjen_moore_test(data):\n",
    "    N = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    z_scores = (data - mean) / std_dev\n",
    "    return np.any(np.abs(z_scores) > 3)  # –ü–æ—Ä–æ–≥ Z-–∑–Ω–∞—á–µ–Ω–∏—è\n",
    "\n",
    "tietjen_moore_result = tietjen_moore_test(data)\n",
    "print(\"Tietjen-Moore Test: Is outlier?\", tietjen_moore_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0490dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. –¢–µ—Å—Ç –°—Ç—å—é–¥–µ–Ω—Ç–∞ (Student's t-test)'''\n",
    "t_statistic, p_value = stats.ttest_1samp(data, 0)\n",
    "print(\"Student's t-test: t-statistic =\", t_statistic, \", p-value =\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''7. –¢–µ—Å—Ç –°–ø–∏—Ä–º–µ–Ω–∞ (Spearman's Rank Correlation Coefficient)'''\n",
    "spearman_corr, spearman_p = stats.spearmanr(data, np.arange(len(data)))\n",
    "print(\"Spearman's Test: Correlation =\", spearman_corr, \", p-value =\", spearman_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''8. –¢–µ—Å—Ç –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏ (Mann-Whitney U Test)'''\n",
    "# –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Å–æ–∑–¥–∞–¥–∏–º –¥–≤–∞ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "data1 = np.array([1, 2, 3, 4, 5])\n",
    "data2 = np.array([5, 6, 7, 8, 9])\n",
    "mann_whitney_result = stats.mannwhitneyu(data1, data2)\n",
    "print(\"Mann-Whitney U Test: U-statistic =\", mann_whitney_result.statistic, \", p-value =\", mann_whitney_result.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''9. –¢–µ—Å—Ç –®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞ (Shapiro-Wilk Test)'''\n",
    "shapiro_stat, shapiro_p = stats.shapiro(data)\n",
    "print(\"Shapiro-Wilk Test: W-statistic =\", shapiro_stat, \", p-value =\", shapiro_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3510c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''10. –¢–µ—Å—Ç –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞ (Kolmogorov-Smirnov Test)'''\n",
    "ks_stat, ks_p = stats.kstest(data, 'norm', args=(np.mean(data), np.std(data)))\n",
    "print(\"Kolmogorov-Smirnov Test: D-statistic =\", ks_stat, \", p-value =\", ks_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611059a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. –ö—Ä–∏—Ç–µ—Ä–∏–π –®–æ–≤–µ–Ω–µ (Chauvenet's Criterion)'''\n",
    "def chauvenet_test(data):\n",
    "    N = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    d = abs(data - mean) / std_dev\n",
    "    p_values = 1 / (2 * N * np.exp(0.5 * (d**2)))\n",
    "    return np.any(p_values < 0.5)\n",
    "\n",
    "chauvenet_result = chauvenet_test(data)\n",
    "print(\"Chauvenet's Criterion: Is outlier?\", chauvenet_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ac196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ (–ø—Ä–∏–º–µ—Ä –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –º–µ–¥–∏–∞–Ω–∞–º–∏ –∏ –º–æ–¥–∞–º–∏)\n",
    "for column in data.columns:\n",
    "    if data[column].dtype != object:\n",
    "        median_value = data[column].median()\n",
    "        data[column].fillna(median_value, inplace=True)\n",
    "    else:\n",
    "        mode_value = data[column].mode()[0]\n",
    "        data[column].fillna(mode_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5146ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "data_cleaned.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''8. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –¥–ª—è –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π'''\n",
    "df['A_missing'] = df['A'].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9066a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóëÔ∏è –£–î–ê–õ–ï–ù–ò–ï –õ–ò–®–ù–ò–• –°–¢–û–õ–ë–¶–û–í\n",
    "print(\"üóëÔ∏è –£–î–ê–õ–ï–ù–ò–ï –õ–ò–®–ù–ò–• –°–¢–û–õ–ë–¶–û–í\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è\n",
    "columns_to_remove = [\n",
    "    'Photo', \n",
    "    'NumberChildrenAtHome', \n",
    "    'AddressLine1', \n",
    "    'RegionImage', \n",
    "    'RegionInfo', \n",
    "    'CustomerStateCode', \n",
    "    'ProductDescription', \n",
    "    'SalesOrderLineNumber', \n",
    "    'StandardCost',  # —Ä–∞–≤–µ–Ω TotalProductCost\n",
    "    'ListPrice',     # —Ä–∞–≤–µ–Ω SalesAmount  \n",
    "    'PromotionKey',\n",
    "    'CustomerCountry', # —Ä–∞–≤–µ–Ω Country\n",
    "    'Group'\n",
    "]\n",
    "\n",
    "print(\"üìã –°–¢–û–õ–ë–¶–´ –î–õ–Ø –£–î–ê–õ–ï–ù–ò–Ø:\")\n",
    "for i, col in enumerate(columns_to_remove, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã\n",
    "existing_columns_to_remove = [col for col in columns_to_remove if col in df.columns]\n",
    "non_existing_columns = [col for col in columns_to_remove if col not in df.columns]\n",
    "\n",
    "print(f\"\\n –°–¢–ê–¢–£–° –°–¢–û–õ–ë–¶–û–í:\")\n",
    "print(f\"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: {len(existing_columns_to_remove)}\")\n",
    "print(f\"   ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–∞–Ω–Ω—ã—Ö: {len(non_existing_columns)}\")\n",
    "\n",
    "if non_existing_columns:\n",
    "    print(\"   üìù –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã:\")\n",
    "    for col in non_existing_columns:\n",
    "        print(f\"      - {col}\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "initial_columns_count = len(df.columns)\n",
    "print(f\"\\nüìä –ò–°–•–û–î–ù–û–ï –ö–û–õ–ò–ß–ï–°–¢–í–û –°–¢–û–õ–ë–¶–û–í: {initial_columns_count}\")\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±—Ü—ã\n",
    "df = df.drop(columns=existing_columns_to_remove, errors='ignore')\n",
    "\n",
    "# –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "final_columns_count = len(df.columns)\n",
    "columns_removed = initial_columns_count - final_columns_count\n",
    "\n",
    "print(f\"\\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢ –£–î–ê–õ–ï–ù–ò–Ø:\")\n",
    "print(f\"   ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {columns_removed}\")\n",
    "print(f\"   ‚Ä¢ –û—Å—Ç–∞–ª–æ—Å—å —Å—Ç–æ–ª–±—Ü–æ–≤: {final_columns_count}\")\n",
    "print(f\"   ‚Ä¢ –°–æ–∫—Ä–∞—â–µ–Ω–∏–µ: {columns_removed}/{initial_columns_count} ({columns_removed/initial_columns_count*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìù –û–°–¢–ê–í–®–ò–ï–°–Ø –°–¢–û–õ–ë–¶–´ ({final_columns_count}):\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\nüëÄ –ü–†–ï–í–¨–Æ –î–ê–ù–ù–´–• –ü–û–°–õ–ï –£–î–ê–õ–ï–ù–ò–Ø:\")\n",
    "display(df.head(2))\n",
    "\n",
    "print(\"‚úÖ –õ–ò–®–ù–ò–ï –°–¢–û–õ–ë–¶–´ –£–î–ê–õ–ï–ù–´!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71cbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ –û–ß–ò–°–¢–ö–ê –ò –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•\n",
    "print(\"üßπ –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•\")\n",
    "print(\"=\" * 50)\n",
    "df = data\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä\n",
    "initial_count = len(df)\n",
    "print(f\"üìä –ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {initial_count}\")\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤\n",
    "df = df.drop_duplicates()\n",
    "duplicates_removed = initial_count - len(df)\n",
    "print(f\"üìä –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "print(\"\\nüìä –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': missing_data,\n",
    "    '–ü—Ä–æ—Ü–µ–Ω—Ç': missing_percent\n",
    "}).sort_values('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', ascending=False)\n",
    "\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏\n",
    "missing_columns = missing_info[missing_info['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] > 0]\n",
    "if len(missing_columns) > 0:\n",
    "    print(\"–ö–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏:\")\n",
    "    display(missing_columns)\n",
    "else:\n",
    "    print(\"‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ\")\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "print(\"\\nüîß –ó–ê–ü–û–õ–ù–ï–ù–ò–ï –ü–†–û–ü–£–°–ö–û–í:\")\n",
    "if 'Color' in df.columns:\n",
    "    df['Color'] = df['Color'].fillna('Not Specified')\n",
    "    print(\"‚úÖ Color: –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º 'Not Specified'\")\n",
    "\n",
    "if 'SubCategory' in df.columns:\n",
    "    df['SubCategory'] = df['SubCategory'].fillna('Unknown')\n",
    "    df['Category'] = df['Category'].fillna('Unknown')\n",
    "    print(\"‚úÖ Category/SubCategory: –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º 'Unknown'\")\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"\\nüîÑ –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–ï –¢–ò–ü–û–í –î–ê–ù–ù–´–•:\")\n",
    "\n",
    "date_columns = ['OrderDate', 'ShipDate', 'BirthDate', 'DateFirstPurchase', 'StartDate']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        print(f\"‚úÖ {col}: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ datetime\")\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "numeric_columns = ['YearlyIncome', 'TotalChildren', 'NumberChildrenAtHome', \n",
    "                  'NumberCarsOwned', 'StandardCost', 'ListPrice', 'DaysToManufacture',\n",
    "                  'OrderQuantity', 'UnitPrice', 'TotalProductCost', 'SalesAmount', 'TaxAmt']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        print(f\"‚úÖ {col}: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "print(\"\\nüéØ –°–û–ó–î–ê–ù–ò–ï –ù–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í:\")\n",
    "\n",
    "if 'OrderDate' in df.columns:\n",
    "    df['OrderYear'] = df['OrderDate'].dt.year\n",
    "    df['OrderMonth'] = df['OrderDate'].dt.month\n",
    "    df['OrderQuarter'] = df['OrderDate'].dt.quarter\n",
    "    df['OrderDayOfWeek'] = df['OrderDate'].dt.day_name()\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ OrderDate\")\n",
    "    \n",
    "    # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ—Å—Ç–∞–≤–∫–∏\n",
    "    if 'ShipDate' in df.columns:\n",
    "        df['DeliveryDays'] = (df['ShipDate'] - df['OrderDate']).dt.days\n",
    "        print(\"‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫ DeliveryDays\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤\n",
    "if 'YearlyIncome' in df.columns:\n",
    "    df['IncomeSegment'] = pd.cut(df['YearlyIncome'], \n",
    "                               bins=[0, 50000, 80000, 100000, float('inf')],\n",
    "                               labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω IncomeSegment\")\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞ –∫–ª–∏–µ–Ω—Ç–∞\n",
    "if 'BirthDate' in df.columns:\n",
    "    df['Age'] = (datetime.now() - df['BirthDate']).dt.days // 365\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫ Age\")\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏\n",
    "if 'SalesAmount' in df.columns and 'TotalProductCost' in df.columns:\n",
    "    df['Profit'] = df['SalesAmount'] - df['TotalProductCost']\n",
    "    df['ProfitMargin'] = (df['Profit'] / df['SalesAmount']) * 100\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω—ã Profit –∏ ProfitMargin\")\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç –æ–±—â–µ–π —Å—É–º–º—ã, –µ—Å–ª–∏ –Ω–µ—Ç\n",
    "if 'UnitPrice' in df.columns and 'OrderQuantity' in df.columns and 'TotalAmount' not in df.columns:\n",
    "    df['TotalAmount'] = df['UnitPrice'] * df['OrderQuantity']\n",
    "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω TotalAmount\")\n",
    "\n",
    "print(f\"\\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢ –û–ß–ò–°–¢–ö–ò:\")\n",
    "print(f\"   ‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {initial_count} —Å—Ç—Ä–æ–∫\")\n",
    "print(f\"   ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(df)} —Å—Ç—Ä–æ–∫\") \n",
    "print(f\"   ‚Ä¢ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}\")\n",
    "print(f\"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\nüëÄ –ü–†–ï–í–¨–Æ –û–ß–ò–©–ï–ù–ù–´–• –î–ê–ù–ù–´–•:\")\n",
    "display(df.head(3))\n",
    "\n",
    "print(\"\\nüìã –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–• –ü–û–°–õ–ï –û–ß–ò–°–¢–ö–ò:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n‚úÖ –î–ê–ù–ù–´–ï –û–ß–ò–©–ï–ù–´ –ò –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–´!\")\n",
    "'''6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö'''\n",
    "data_cleaned.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "print(\"–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32a856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•\n",
    "print(\"üîç –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"üìà –û–°–ù–û–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê (—á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏):\")\n",
    "print(f\"üìä –ù–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(numeric_cols)}\")\n",
    "\n",
    "if len(numeric_cols) > 0:\n",
    "    display(df[numeric_cols].describe())\n",
    "else:\n",
    "    print(\"‚ùå –ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nüìä –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ({len(categorical_cols)}):\")\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    for i, col in enumerate(categorical_cols[:8], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 8\n",
    "        unique_count = df[col].nunique()\n",
    "        print(f\"   {i}. {col}: {unique_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\")\n",
    "        if unique_count <= 10:\n",
    "            value_counts = df[col].value_counts()\n",
    "            print(f\"      –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {dict(value_counts)}\")\n",
    "        else:\n",
    "            print(f\"      –ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π: {list(df[col].unique()[:5])}\")\n",
    "    \n",
    "    if len(categorical_cols) > 8:\n",
    "        print(f\"   ... –∏ –µ—â–µ {len(categorical_cols) - 8} –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\")\n",
    "else:\n",
    "    print(\"‚ùå –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "\n",
    "# –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "date_cols = df.select_dtypes(include=['datetime64']).columns\n",
    "print(f\"\\nüïê –í–†–ï–ú–ï–ù–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï ({len(date_cols)}):\")\n",
    "\n",
    "if len(date_cols) > 0:\n",
    "    for i, col in enumerate(date_cols, 1):\n",
    "        date_range = f\"{df[col].min().date()} - {df[col].max().date()}\"\n",
    "        print(f\"   {i}. {col}: {date_range}\")\n",
    "else:\n",
    "    print(\"‚ùå –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "\n",
    "# –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(f\"\\nüìã –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–•:\")\n",
    "print(f\"   ‚Ä¢ –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫\")\n",
    "print(f\"   ‚Ä¢ –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(f\"      - –ß–∏—Å–ª–æ–≤—ã–µ: {len(numeric_cols)}\")\n",
    "print(f\"      - –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ: {len(categorical_cols)}\")\n",
    "print(f\"      - –í—Ä–µ–º–µ–Ω–Ω—ã–µ: {len(date_cols)}\")\n",
    "print(f\"      - –î—Ä—É–≥–∏–µ: {df.shape[1] - len(numeric_cols) - len(categorical_cols) - len(date_cols)}\")\n",
    "\n",
    "# –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "missing_total = df.isnull().sum().sum()\n",
    "missing_percent = (missing_total / (df.shape[0] * df.shape[1])) * 100\n",
    "print(f\"   ‚Ä¢ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {missing_total} ({missing_percent:.2f}%)\")\n",
    "\n",
    "print(\"\\nüëÄ –ü–ï–†–í–´–ï 3 –°–¢–†–û–ö–ò –î–ê–ù–ù–´–•:\")\n",
    "display(df.head(3))\n",
    "\n",
    "print(\"‚úÖ –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
